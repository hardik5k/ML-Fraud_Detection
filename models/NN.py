# -*- coding: utf-8 -*-
"""NN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Gx7SHRgE8YLUVA_8Yy_yhH6zJocOs00o
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt
import seaborn as sns


from sklearn import model_selection
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from imblearn.over_sampling import RandomOverSampler
from imblearn.under_sampling import RandomUnderSampler
from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,roc_auc_score, f1_score,plot_confusion_matrix,plot_roc_curve

from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense
from keras import optimizers
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

import numpy as np 
import pandas as pd
pd.set_option("display.max_rows", None, "display.max_columns", None)

train = pd.read_csv("../input/preprocessedfraud/train_preprocessed.csv")
test = pd.read_csv("../input/preprocessedfraud/test_preprocessed.csv")

train.shape, test.shape

def submit(y_pred):
    sample = pd.read_csv('../input/submissiontemplate/submission.csv')
    sample.isFraud = y_pred
    sub_name = 'submission.csv'
    sample.to_csv(sub_name, index=False)

y = train[['isFraud']]

X = train.drop(['isFraud'], axis = 1)
del train

# Train-test split
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.25, random_state = 42)

X_train=X_train.to_numpy()
y_train=y_train.to_numpy()
X_val=X_val.to_numpy()
y_val=y_val.to_numpy()

y_train = y_train.ravel()
y_val = y_val.ravel()

y_train

"""## Hyperparamter Tuning"""

batch_size = 128
input_dim = X_train.shape[1]
output_dim = 2

# Dataset class for DataLoader
class Data(Dataset):
    def __init__(self, x_train, y_train):
        self.x=torch.from_numpy(x_train)
        self.y=torch.from_numpy(y_train)
        self.len=self.x.shape[0]
    def __getitem__(self,index):      
        return self.x[index], self.y[index]
    def __len__(self):
        return self.len

train_ds = Data(X_train, y_train)
val_ds = Data(X_val, y_val)

train_loader = DataLoader(train_ds, batch_size)
val_loader = DataLoader(val_ds, batch_size * 2)

def get_default_device():
    if torch.cuda.is_available():
        return torch.device('cuda')
    else:
        return torch.device('cpu')

device = get_default_device()

def to_device(data, device):
    if isinstance(data, (list,tuple)):
        return [to_device(x, device) for x in data]
    return data.to(device, non_blocking=True)

class DeviceDataLoader():
    def __init__(self, dl, device):
        self.dl = dl
        self.device = device
        
    def __iter__(self):
        for b in self.dl: 
            yield to_device(b, self.device)

    def __len__(self):
        return len(self.dl)

train_loader = DeviceDataLoader(train_loader, device)
val_loader = DeviceDataLoader(val_loader, device)

def accuracy(y_p, y):
    _, preds = torch.max(y_p, dim=1)
    submit(preds)
    return torch.tensor(torch.sum(preds == y).item() / len(preds))


class Net(nn.Module):
    
    def validation_step(self, batch):
        images, labels = batch 
        out = self(images.float())                    # Generate predictions
        loss = nn.functional.cross_entropy(out, labels)   # Calculate loss
        acc = accuracy(out, labels)           # Calculate accuracy
        return {'val_loss': loss, 'val_acc': acc}
        
    def validation_epoch_end(self, outputs):
        batch_losses = [x['val_loss'] for x in outputs]
        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses
        batch_accs = [x['val_acc'] for x in outputs]
        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies
        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}
    def epoch_end(self, epoch, result):
        print("Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}".format(epoch, result['val_loss'], result['val_acc']))
        
    def __init__(self, input_size, output_size):
        super(Net, self).__init__()
        self.linear1 = nn.Linear(input_size, 256)
        self.linear2 = nn.Linear(256, 128)
        self.linear3 = nn.Linear(128, output_size)
        
    def forward(self, x):
        out = nn.functional.relu(self.linear1(x))
        out = nn.functional.relu(self.linear2(out))
        out = self.linear3(out)
        
        return out

def evaluate(model, val_loader):
    outputs = [model.validation_step(batch) for batch in val_loader]
    return model.validation_epoch_end(outputs)

def fit(train_loader, val_loader, model, lr, epochs):
    loss_history = []
    optimizer = torch.optim.SGD(model.parameters(), lr)
    for epoch in range(epochs):
        for x, y in train_loader:
            optimizer.zero_grad()
            z = model(x.float())
            loss = nn.functional.cross_entropy(z, y)
            loss.backward()
            optimizer.step()
            
        result = evaluate(model, val_loader)
        model.epoch_end(epoch, result)
        loss_history.append(result)
    return loss_history

model = to_device(Net(input_dim, output_dim), device)

fit(train_loader, val_loader, model, 0.001, 50)
